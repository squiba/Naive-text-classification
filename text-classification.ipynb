{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification ( Naive Bayes )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "20newsgroup dataset will be downloaded and divided in training(60%) and test(40%) dataset. [source code for fetching the dataset](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/datasets/twenty_newsgroups.py) (see the fetch_20newgroup function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of examples: 18846\n",
      "training examples: 11314\n",
      "test examples: 7532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "dataset = fetch_20newsgroups(subset='all',shuffle=True,random_state=42,data_home='scikit_learn_data/')\n",
    "twenty_train = fetch_20newsgroups(subset='train',shuffle=True,random_state=42,data_home='scikit_learn_data/')\n",
    "twenty_test = fetch_20newsgroups(subset='test',shuffle=True,random_state=42,data_home='scikit_learn_data/')\n",
    "\n",
    "print(\"no of examples:\", len(dataset.data))\n",
    "print(\"training examples:\",len(twenty_train.data))\n",
    "print(\"test examples:\", len(twenty_test.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Features from text data\n",
    "Two different type of features will be used. [source code for feature extraction](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/text.py) (see the CounVectorizer and TfidfTransformer class)  \n",
    "For each example\n",
    "1. count vectorizer = word_id: no of words present\n",
    "2. tfidf transformer = word_id: tfidf value  \n",
    "[Read this](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) to learn more about how feature extraction is done in scikit-learn.\n",
    "\n",
    "Note:  \n",
    "1. fit_transform: fit acording to the data provided and than tranform text into vector as mentioned above\n",
    "2. transform: transorm the data into vector as already fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# tokenizing the text\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_test_counts = count_vect.transform(twenty_test.data)\n",
    "\"\"\"\n",
    "#saving the vocabulary\n",
    "import os\n",
    "import joblib\n",
    "Voc_dir = \"vocabulary/\"\n",
    "Voc_path = os.path.join(Voc_dir,'Voc.pkl')\n",
    "if not os.path.exists(Voc_dir):\n",
    "    os.makedirs(Voc_dir)\n",
    "joblib.dump(vectorizer.vocabulary_,Voc_path)\n",
    "loaded_vec = CountVectorizer(vocabulary=joblib.load(Voc_path))\n",
    "X_test_counts = count_vect.transform(twenty_test.data)\n",
    "\"\"\"\n",
    "\n",
    "# calculating tfidf (Term_frequency * inverse_document_frequency)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the Naive Bayes Model\n",
    "[Naive Bayes model](http://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes) with \n",
    "1. smoothing prior alpha =1(in each document add one instance of every word) and \n",
    "2. fit_prior = false ( initial probability of classes will be taken equal)  \n",
    "[source code for naive bayes](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/naive_bayes.py) (see the MultinomialNB class)\n",
    "\n",
    "Two models are generated for different typr of features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_naive_count = MultinomialNB(alpha=1,fit_prior='false').fit(X_train_counts, twenty_train.target)\n",
    "clf_naive_tfidf = MultinomialNB(alpha=1,fit_prior='false').fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model\n",
    "saving the trained model on the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_models/naive_tfidf/Naive_tfidf.pkl',\n",
       " 'trained_models/naive_tfidf/Naive_tfidf.pkl_01.npy',\n",
       " 'trained_models/naive_tfidf/Naive_tfidf.pkl_02.npy',\n",
       " 'trained_models/naive_tfidf/Naive_tfidf.pkl_03.npy',\n",
       " 'trained_models/naive_tfidf/Naive_tfidf.pkl_04.npy',\n",
       " 'trained_models/naive_tfidf/Naive_tfidf.pkl_05.npy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ckeck for directory and make them\n",
    "import os\n",
    "naive_count_dir = \"trained_models/naive_count\"\n",
    "naive_tfidf_dir = \"trained_models/naive_tfidf\"\n",
    "naive_count_path = os.path.join(naive_count_dir,'Naive_count.pkl')\n",
    "naive_tfidf_path = os.path.join(naive_tfidf_dir,'Naive_tfidf.pkl')\n",
    "if not os.path.exists(naive_count_dir):\n",
    "    os.makedirs(naive_count_dir)\n",
    "if not os.path.exists(naive_tfidf_dir):\n",
    "    os.makedirs(naive_tfidf_dir)\n",
    "    \n",
    "# save the model\n",
    "import joblib\n",
    "joblib.dump(clf_naive_count,naive_count_path)\n",
    "joblib.dump(clf_naive_tfidf,naive_tfidf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the class of an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism :       6.928448142e-08\n",
      "comp.graphics :       0.000294394674302\n",
      "comp.os.ms-windows.misc :       3.39993180912e-10\n",
      "comp.sys.ibm.pc.hardware :       0.00458462094315\n",
      "comp.sys.mac.hardware :       0.00198745906265\n",
      "comp.windows.x :       1.75009969537e-06\n",
      "misc.forsale :       0.989085666752\n",
      "rec.autos :       0.000205423904541\n",
      "rec.motorcycles :       0.00259759864731\n",
      "rec.sport.baseball :       6.00088470696e-07\n",
      "rec.sport.hockey :       2.77092388721e-07\n",
      "sci.crypt :       0.000166082650813\n",
      "sci.electronics :       0.000632228152589\n",
      "sci.med :       9.42425086419e-06\n",
      "sci.space :       4.43272817046e-05\n",
      "soc.religion.christian :       2.65777303116e-06\n",
      "talk.politics.guns :       3.24803194357e-05\n",
      "talk.politics.mideast :       4.33967715101e-07\n",
      "talk.politics.misc :       0.000353475931864\n",
      "talk.religion.misc :       1.02878338456e-06\n",
      "\n",
      "category:  misc.forsale\n"
     ]
    }
   ],
   "source": [
    "test_example = [\"forsale: this item is fantastic.buy it today and get free offer.best cheap quality discount\"]\n",
    "test_example_count = count_vect.transform(test_example)\n",
    "probs = clf_naive_count.predict_proba(test_example_count)[0] # alternate: predict_log_proba\n",
    "\n",
    "for i in range(len(twenty_train.target_names)):\n",
    "    print(twenty_train.target_names[i],\":      \",probs[i])\n",
    "    \n",
    "print(\"\\ncategory: \",twenty_train.target_names[clf_naive_count.predict(test_example_count)[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a txt file and predict its class\n",
    "Classifing the (About the Research Topic) section on \"[computational neuroscience of deep brain simulation](http://journal.frontiersin.org/researchtopic/5705/computational-neuroscience-of-deep-brain-stimulation)\"  \n",
    "As expected both the models classify it in science (medician) category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "count_category:  sci.med\n",
      "\n",
      "tfidf_category:  sci.med\n"
     ]
    }
   ],
   "source": [
    "file = open('neuroscience.txt')\n",
    "file_data = file.read()\n",
    "file_data_count = count_vect.transform([file_data])\n",
    "file_data_tfidf = tfidf_transformer.transform(file_data_count)\n",
    "print(\"\\ncount_category: \",twenty_train.target_names[clf_naive_count.predict(file_data_count)[0]])\n",
    "print(\"\\ntfidf_category: \",twenty_train.target_names[clf_naive_tfidf.predict(file_data_tfidf)[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the performance on the test dataset\n",
    "As expected tfidf features gives some better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "count_accuracy: 0.772835900159\n",
      "\n",
      "tfidf_accuracy: 0.77389803505\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "naive_count_predicted = clf_naive_count.predict(X_test_counts)\n",
    "naive_tfidf_predicted = clf_naive_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\ncount_accuracy:\",np.mean(naive_count_predicted == twenty_test.target))\n",
    "print(\"\\ntfidf_accuracy:\",np.mean(naive_tfidf_predicted == twenty_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ten most discriminative terms per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism :  livesey atheists have this caltech are be not god edu keith it and you in that is to of the\n",
      "comp.graphics :  files or have 3d this on image you that from edu in for it is and graphics of to the\n",
      "comp.os.ms-windows.misc :  on driver from with files have that you dos in file for of and edu is it to the windows\n",
      "comp.sys.ibm.pc.hardware :  have com controller that on in bus edu with for card ide is of it drive and scsi to the\n",
      "comp.sys.mac.hardware :  this drive my have from you on with that for in it is and of edu apple mac to the\n",
      "comp.windows.x :  you widget from that on edu this for com server it mit in motif and is of window to the\n",
      "misc.forsale :  condition distribution with university it new from in you or shipping offer of 00 to and edu the for sale\n",
      "rec.autos :  was are they have my for on cars edu com that is you it in of and to car the\n",
      "rec.motorcycles :  ride re from was edu for that is on my dod you it com in of and bike to the\n",
      "rec.sport.baseball :  you players it his game they for team was year that is baseball and of in to he edu the\n",
      "rec.sport.hockey :  play on you it for was is nhl that edu ca game he team and hockey of in to the\n",
      "sci.crypt :  as keys they you for this com be in it chip that encryption is and clipper key of to the\n",
      "sci.electronics :  if with this be have are from com on that for edu you it in is and of to the\n",
      "sci.med :  for not are you com this msg gordon banks geb edu pitt that it in and is to of the\n",
      "sci.space :  this was moon alaska be you on for henry edu it that is nasa in and to of space the\n",
      "soc.religion.christian :  have was jesus this as be are he you not we it in and is god that to of the\n",
      "talk.politics.guns :  be have as this are for guns com edu they it is you that gun and in of to the\n",
      "talk.politics.mideast :  as armenian was edu by are turkish jews not it is you israeli that israel in and to of the\n",
      "talk.politics.misc :  on optilink this be as for cramer com are not edu it is you and in that of to the\n",
      "talk.religion.misc :  christian as be are com he edu jesus not it sandvik god you in is that and to of the\n"
     ]
    }
   ],
   "source": [
    "feature_names = count_vect.get_feature_names()\n",
    "feature_names = np.asarray(feature_names)\n",
    "for i, label in enumerate(twenty_train.target_names):\n",
    "    top10 = np.argsort(clf_naive_tfidf.coef_[i])[-20:]\n",
    "    print(label,\": \", \" \".join(feature_names[top10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(py3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
